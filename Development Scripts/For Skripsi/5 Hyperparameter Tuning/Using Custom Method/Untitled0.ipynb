{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOYO3PeYbVfYBr9K89v9uOf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FVFB8A5R8sd0"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import tensorflow_datasets as tfds\n","from sklearn.model_selection import train_test_split\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","\n","class CNNModel(BaseEstimator, ClassifierMixin):\n","  def __init__(\n","      self,\n","      input_shape,\n","      layer_metadata,\n","      convolution_part=['conv1d'],\n","      intermediate_part=['flatten'],\n","      dense_part=['dense'],\n","      convolution_hyperparameter=[{'filters':16, 'kernel_size':3, 'activation':'relu'}],\n","      intermediate_hyperparameter=[{}],\n","      dense_hyperparameter=[{'units':32, 'activation':'relu'}],\n","      optimizer='adam'\n","  ):\n","    self.input_shape = input_shape\n","    self.layer_metadata = layer_metadata\n","    self.convolution_part = convolution_part\n","    self.intermediate_part = intermediate_part\n","    self.dense_part = dense_part\n","    self.convolution_hyperparameter = convolution_hyperparameter\n","    self.intermediate_hyperparameter = intermediate_hyperparameter\n","    self.dense_hyperparameter = dense_hyperparameter\n","    self.optimizer = optimizer\n","    self.model = self.build_model(input_shape, convolution_part, intermediate_part, dense_part, convolution_hyperparameter, intermediate_hyperparameter, dense_hyperparameter, optimizer)\n","\n","  def build_model(\n","      self,\n","      input_shape,\n","      convolution_part,\n","      intermediate_part,\n","      dense_part,\n","      convolution_hyperparameter,\n","      intermediate_hyperparameter,\n","      dense_hyperparameter,\n","      optimizer,\n","  ):\n","\n","    def fix_hyperparameter_type(layer, hyperparameter, layer_metadata, warnings=True):\n","      for layer_info in layer_metadata:\n","        if(layer == layer_info['layer']):\n","          for params in layer_info['hyperparameter']:\n","            val = hyperparameter.get(params['param'], params['default'])\n","            if(type(val) != params['type']):\n","              if(warnings): print(\"Hyperparameter \", params['param'], \" Have Invalid Data Type! Using Default..\")\n","              hyperparameter[params['param']] = params['default']\n","            else:\n","              hyperparameter[params['param']] = val\n","        else:\n","          pass\n","      return hyperparameter\n","\n","    model = models.Sequential()\n","    model.add(layers.Input(input_shape))\n","\n","    # Convolution Part\n","    for layer, hyperparameter in zip(convolution_part, convolution_hyperparameter):\n","      hyperparameter = fix_hyperparameter_type(layer, hyperparameter, self.layer_metadata)\n","\n","      if(layer == 'conv1d'):\n","        model.add(layers.Conv1D(filters=hyperparameter['filters'], kernel_size=hyperparameter['kernel_size'], activation=hyperparameter['activation']))\n","      elif(layer == 'maxpooling1d'):\n","        model.add(layers.MaxPooling1D(pool_size=hyperparameter['pool_size']))\n","      else:\n","        print(\"'Convolution Part' Layer Invalid!\")\n","        return None\n","\n","    # Intermediate Part\n","    for layer, hyperparameter in zip(intermediate_part, intermediate_hyperparameter):\n","      hyperparameter = fix_hyperparameter_type(layer, hyperparameter, self.layer_metadata)\n","\n","      if(layer == 'flatten'):\n","        model.add(layers.Flatten())\n","      else:\n","        print(\"'Intermediate Part' Layer Invalid!\")\n","        return None\n","\n","    # Dense Part\n","    for layer, hyperparameter in zip(dense_part, dense_hyperparameter):\n","      hyperparameter = fix_hyperparameter_type(layer, hyperparameter, self.layer_metadata)\n","\n","      if(layer == 'dense'):\n","        model.add(layers.Dense(units=hyperparameter['units'], activation=hyperparameter['activation']))\n","      else:\n","        print(\"'Dense Part' Layer Invalid!\")\n","        return None\n","\n","    model.add(layers.Dense(2, activation='softmax'))\n","\n","    # Compile the model\n","    model.compile(optimizer=optimizer,\n","                loss='sparse_categorical_crossentropy',\n","                metrics=[\n","                    'accuracy'\n","                ])\n","\n","    return model\n","\n","  def fit(self, X_train, y_train, X_test, y_test, epochs, verbose=1, callbacks=[]):\n","    self.model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=verbose, callbacks=callbacks)\n","\n","  def score(self, X, y):\n","    loss, accuracy = self.model.evaluate(X, y, verbose=0)\n","    loss_inverse = 1/(loss+1e-20)\n","\n","    return loss_inverse\n","\n","  def evaluate(self, X, y, verbose=1):\n","    # Evaluate the model on the test set\n","    loss, accuracy = self.model.evaluate(X, y, verbose=0)\n","\n","    if(verbose != 0):\n","      print(f\"Loss: %.3f%%\" % (loss*100) )\n","      print(f\"Accuracy: %.3f%%\" % (accuracy*100) )\n","\n","    return loss, accuracy\n","\n","  def summary(self):\n","    self.model.summary()\n","\n","  def predict(self, X):\n","    return self.model.predict(X, verbose=0)\n","\n","  def save(self, path, save_format='keras'):\n","    return self.model.save(path, save_format)"]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score\n","\n","class MetricsCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, validation_data=()):\n","        super(MetricsCallback, self).__init__()\n","        self.validation_data = validation_data\n","        self.logs = {}\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        if not self.validation_data:\n","            raise RuntimeError(\"Requires validation_data.\")\n","\n","        X_val, y_val = self.validation_data\n","        y_pred = self.model.predict(X_val, verbose=0)\n","\n","        # Convert one-hot encoded labels to class labels\n","        y_pred = np.argmax(y_pred, axis=1)\n","\n","        # Compute Metrics score\n","        f1score = f1_score(y_val, y_pred, average='micro')\n","        roc_auc = roc_auc_score(y_val, y_pred, average='micro')\n","\n","        # Add Metrics score to logs\n","        self.logs['roc_auc'] = roc_auc\n","        self.logs['f1score'] = f1score"],"metadata":{"id":"ueRWwTw19YrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.random.set_seed(37)\n","random.seed(37)\n","\n","X_train, X_val, y_train, y_val = prep_data(df_raw)\n","\n","log = None\n","\n","schema_log = [\n","    row.to_dict()\n","    for index, row in\n","    log_raw[\n","        ['convolution_part', 'convolution_hyperparameter', 'dense_part', 'dense_hyperparameter', 'input_shape', 'layer_metadata']\n","    ].iterrows()\n","]\n","\n","input_shape = X_train.shape[1:]\n","output_shape = 1\n","\n","param_grid = {\n","  'n_conv': [1, 2, 3],\n","  'n_dense':[1, 2, 3],\n","  'conv_layer':['conv1d', 'maxpooling1d'],\n","  'dense_layer':['dense'],\n","  'filters':[2, 4, 8],\n","  'kernel_size':[3],\n","  'units': [16, 32, 64],\n","  'activation': ['relu']\n","}\n","\n","def save_result(save_state, target_path):\n","  log.to_csv(target_path, index=False)\n","\n","def get_schema_combination(part_name, n_layer, layer_values, layer_metadata, param_grid):\n","  schema_combination = []\n","  for n in n_layer:\n","    part_combination=itertools.product(layer_values, repeat=n)\n","\n","    for part in part_combination:\n","      hyperparameters = []\n","\n","      for selected_layer in part:\n","\n","        # Get selected layers's possible hyperparameters\n","        hyperparameter_values = {}\n","        for layer in layer_metadata:\n","          if(selected_layer == layer['layer']):\n","            for params in layer['hyperparameter']:\n","              hyperparameter_values[params['param']] = [params['default']]\n","              if params['param'] in list(param_grid):\n","                hyperparameter_values[params['param']] = param_grid[params['param']]\n","\n","        # get hyperparameter combination to grid search\n","        hyperparameter_combination = []\n","        for combination in list(itertools.product(*hyperparameter_values.values())):\n","          layer_hyperparameter = {}\n","          for key, val in zip(hyperparameter_values.keys(), combination):\n","            layer_hyperparameter[key] = val\n","          hyperparameter_combination.append(layer_hyperparameter)\n","\n","        hyperparameters.append(hyperparameter_combination)\n","\n","      for hyperparameter in list(itertools.product(*hyperparameters)):\n","        schema = {part_name+'_part': list(part), part_name+'_hyperparameter': list(hyperparameter)}\n","        schema_combination.append(schema)\n","\n","  return schema_combination\n","\n","conv_shcema = get_schema_combination(part_name='convolution',\n","                       n_layer = param_grid.get('n_conv', [1]),\n","                       layer_values = param_grid.get('conv_layer', ['conv1d']),\n","                       layer_metadata=layer_metadata,\n","                       param_grid=param_grid)\n","\n","dense_schema = get_schema_combination(part_name='dense',\n","                       n_layer = param_grid.get('n_dense', [1]),\n","                       layer_values = param_grid.get('dense_layer', ['dense']),\n","                       layer_metadata=layer_metadata,\n","                       param_grid=param_grid)\n","\n","model_schema_combination = []\n","for schema in itertools.product(conv_shcema, dense_schema):\n","  model_schema = {}\n","  for schema_dict in schema:\n","    model_schema.update(schema_dict)\n","\n","  model_schema_combination.append(model_schema)\n","\n","print(len(model_schema_combination))\n","print(model_schema_combination[0])\n","print(model_schema_combination[-1])"],"metadata":{"id":"NdxABL-I-Hby"},"execution_count":null,"outputs":[]}]}